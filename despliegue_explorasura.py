# -*- coding: utf-8 -*-
"""Despliegue-ExploraSura.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QWDligWTjrBDgJ244L164wdU0D06qpKe

# Despliegue

- Cargamos el modelo
- Cargamos los datos futuros
- Preparar los datos futuros
- Aplicamos el modelo para la predicción
"""

#Importamos librerías básicas
import pandas as pd # manipulacion dataframes
import numpy as np  # matrices y vectores
import matplotlib.pyplot as plt #gráfica

#Cargamos el modelo
import pickle
filename = 'modelo_class_red_neuronal.pkl'

modelNN,labelencoder,variables, min_max_scaler = pickle.load(open(filename, 'rb'))

#Cargamos los datos futuros
#data = pd.read_csv("Datos_futuros_ExploraSura.csv", sep=';')
#data.head()

#Se crea interfaz gráfica con streamlit para captura de los datos

import streamlit as st

st.title('Prediccion de Clusters predecir de forma automática el clúster al que pertenece, facilitando así la toma de decisiones anticipadas y focalizadas')

Edad = st.slider('Edad', min_value=0, max_value=111, value=20, step=1)
Sexo = st.selectbox('Sexo', ['M', 'F'])
Nivel_Estudios =('Nivel_Estudios', ["''SIN NIVEL EDUCATIVO''","'TECNICA'","'SECUNDARIA'","'PRIMARIA'","'PROFESIONAL'","'ESPECIALIZACION'","'TECNOLOGICA'","'MAESTRIA'","'OTRO'","'DOCTORADO/POSTDOCTORADO'"])
Regimen = st.selectbox('Regimen', ["'CONTRIBUTIVO'","'SUBSIDIADO'"])
Regional = st.selectbox('Regional', ["'REGIONAL ANTIOQUIA'","'REGIONAL EJE CAFETERO'","'REGIONAL NORTE'","'REGIONAL CENTRO'","'REGIONAL OCCIDENTE'"])
Estado_Civil = st.selectbox('Estado_Civil', ["'SOLTERO/A'","'CASADO/A'","'DIVORCIADO/A'","'VIUDO/A'"])
Nivel_Ingresos = st.selectbox('Nivel_Ingresos', ["'COTIZANTES CON INGRESOS INFERIORES A 2 SMLMV'", "'COTIZANTES CON INGRESOS SUPERIORES A 5 SMLMV'","','COTIZANTES CON INGRESOS ENTRE 2 Y 5 SMLMV'","'NIVEL 1 DEL SISBEN'","'NIVEL 2 DEL SISBEN"])
Ind_Masa_Corporal = st.selectbox('Ind_Masa_Corporal', ["'BAJO PESO'","'NORMAL'","'SOBREPESO'","'OBESIDAD'"])
Ind_Ejercicio = st.selectbox('Ind_Ejercico', ["'ND'","'N'","'S'"])

#Dataframe
datos = [[Sexo,Edad,Nivel_Estudios,Regional,Regimen,Nivel_Ingresos,Estado_Civil,Ind_Masa_Corporal,Ind_Ejercicio]]
data = pd.DataFrame(datos, columns=['Edad','Sexo','Nivel_Estudios','Regimen','Regional','Estado_Civil','Nivel_Ingresos','Ind_Masa_Corporal','Ind_Ejercico']) #Dataframe con los mismos nombres de variables

data.info ()

#Se realiza la preparación
data_preparada=data.copy()

data_preparada['Sexo']=data_preparada['Sexo'].astype('category')
data_preparada['Nivel_Estudios']=data_preparada['Nivel_Estudios'].astype('category')
data_preparada['Regional']=data_preparada['Regional'].astype('category')
data_preparada['Regimen']=data_preparada['Regimen'].astype('category')
data_preparada['Nivel_Ingresos']=data_preparada['Nivel_Ingresos'].astype('category')
data_preparada['Estado_Civil']=data_preparada['Estado_Civil'].astype('category')
data_preparada['Ind_Masa_Corporal']=data_preparada['Ind_Masa_Corporal'].astype('category')
data_preparada['Ind_Ejercicio']=data_preparada['Ind_Ejercicio'].astype('category')
data_preparada.info()

data_preparada = pd.get_dummies(data_preparada, columns=['Sexo','Regimen', 'Nivel_Estudios','Regional','Nivel_Ingresos',
                                     'Estado_Civil','Ind_Masa_Corporal',
                                     'Ind_Ejercicio'], drop_first=False) #En despliegue no se borran dummies, siempre el drop_first va en falso porque nunca se borra dummy
data_preparada.head()

#Se adicionan las columnas faltantes, con el reindex se completa las variables faltantes con zeros
data_preparada= data_preparada.reindex(columns=variables,fill_value=0)
data_preparada.head()

#Normalizacion de variables numéricas
from sklearn.preprocessing import MinMaxScaler

min_max_scaler = MinMaxScaler()
variables_a_normalizar=['Edad']
min_max_scaler.fit(data_preparada[variables_a_normalizar]) #Ajuste de parámetro
data_preparada[variables_a_normalizar]= min_max_scaler.transform(data_preparada[variables_a_normalizar])
data_preparada.head()

"""# **Predicciones**"""

#Hacemos la predicción con la red neuronal
Y_fut = modelNN.predict(data_preparada)
print(Y_fut)

#Hacemos la predicción con Red Neuronal
Y_fut = modelNN.predict(data_preparada)
data['Neural_Network_cluster']=labelencoder.inverse_transform(Y_fut)
data.head()

#Predicciones Finales
data

